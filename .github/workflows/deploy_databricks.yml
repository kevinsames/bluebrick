---
name: Deploy Databricks Artifacts

'on':
  push:
    branches: [main]
    paths:
      - 'src/notebooks/**'
      - '.github/workflows/deploy_databricks.yml'
  workflow_dispatch: {}
  release:
    types: [published]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Databricks CLI
        uses: databricks/setup-cli@v2

      - name: Configure Databricks auth
        shell: bash
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          if [[ -z "$DATABRICKS_HOST" || -z "$DATABRICKS_TOKEN" ]]; then
            echo "DATABRICKS_HOST and DATABRICKS_TOKEN secrets are required" >&2
            exit 1
          fi
          databricks auth profiles-location set ./
          printf "%s\n%s\n" "$DATABRICKS_HOST" "$DATABRICKS_TOKEN" | databricks configure --token

      - name: Import notebooks and configs to workspace
        env:
          USERNAME: ${{ github.actor }}
        run: |
          BASE="/Users/${USERNAME}/bluebrick"
          databricks workspace mkdirs "$BASE"
          databricks workspace import-dir --overwrite src/notebooks "$BASE/notebooks"
          databricks workspace import-dir --overwrite configs "$BASE/configs"
          databricks workspace import-dir --overwrite src/bluebrick "$BASE/bluebrick"

      - name: Ensure/Run quickstart job
        env:
          USERNAME: ${{ github.actor }}
        run: |
          BASE="/Users/${USERNAME}/bluebrick"
          JOB_PAYLOAD=$(jq -n \
            --arg base "$BASE" \
            '{
              name: "bluebrick-quickstart",
              tasks: [
                {
                  task_key: "quickstart",
                  notebook_task: {
                  notebook_path: ($base + "/notebooks/00_quickstart_etl.ipynb"),
                    source: "WORKSPACE"
                  },
                  job_cluster_key: "bluebrick_job_cluster"
                }
              ],
              job_clusters: [
                {
                  job_cluster_key: "bluebrick_job_cluster",
                  new_cluster: {
                    spark_version: "14.3.x-scala2.12",
                    node_type_id: "Standard_DS3_v2",
                    num_workers: 1,
                    data_security_mode: "SINGLE_USER"
                  }
                }
              ]
            }')

          # Try to find existing job by name
          JOB_ID=$(databricks jobs list --output JSON \
            | jq -r '.jobs[] | select(.settings.name=="bluebrick-quickstart") | .job_id' \
            | head -n1)
          if [[ -z "$JOB_ID" || "$JOB_ID" == "null" ]]; then
            echo "Creating job 'bluebrick-quickstart'"
            JOB_ID=$(echo "$JOB_PAYLOAD" | databricks jobs create --json-file - | jq -r '.job_id')
          else
            echo "Updating job 'bluebrick-quickstart' ($JOB_ID)"
            echo "$JOB_PAYLOAD" | databricks jobs reset --job-id "$JOB_ID" --json-file - >/dev/null
          fi

          echo "Triggering run for job $JOB_ID"
          databricks jobs run-now --job-id "$JOB_ID"
